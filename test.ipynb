{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from main import do\n",
    "from main import do_v2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import contents2count, contents2count_v2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from preprocess import AE2\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import random\n",
    "from glob import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2ascii(x):\n",
    "    output = ''\n",
    "    for i in range(0,len(x),2):\n",
    "        tmp = str(x[i:i+2])\n",
    "        output+=chr(int(tmp,16))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_opendata(path):\n",
    "    datas_ = []\n",
    "    for paths in glob(os.path.join(path,'*.txt')):\n",
    "        datas = []\n",
    "        with open(paths) as f:\n",
    "            event=''\n",
    "            tmp1=''\n",
    "            tmp2=''\n",
    "            for i in f.readlines():\n",
    "                if (i[:3]=='GET' )| (i[:4]=='POST'):\n",
    "                    datas.append(event)\n",
    "                    event = i\n",
    "                else:\n",
    "                    event+=i\n",
    "        datas_.append(datas[1:])\n",
    "\n",
    "\n",
    "\n",
    "    labels = list(map(lambda x: np.zeros(len(x)), datas_))\n",
    "    labels[0] +=1\n",
    "\n",
    "    del datas\n",
    "    tr1,te1 =  train_test_split(datas_[0],test_size=0.2,shuffle=True,random_state=666)\n",
    "    tr2,te2 =  train_test_split(datas_[1],test_size=0.2,shuffle=True,random_state=666)\n",
    "\n",
    "    train = tr1 + tr2\n",
    "    train_label = np.array([0]*len(tr1) + [1]*len(tr2))\n",
    "    test = te1 + te2\n",
    "    test_label = np.array([0]*len(te1) + [1]*len(te2))\n",
    "\n",
    "    train = list(map(lambda x: \"\\n\".join([x.splitlines()[0],x.splitlines()[-2]]) , train))\n",
    "    test_ = list(map(lambda x: \"\\n\".join([x.splitlines()[0],x.splitlines()[-2]]) , test))\n",
    "    return train, test_ ,train_label,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(res,test,th):\n",
    "    \n",
    "    cluster_center = {}\n",
    "    for i in res[1]:\n",
    "        cluster_center[i] = np.mean(res[1][i],axis=0)\n",
    "\n",
    "    ress = []\n",
    "    keys = list(cluster_center.keys())\n",
    "    cluster_center_vectors = np.array(list(cluster_center.values()))\n",
    "\n",
    "    for ev in test:\n",
    "        ev = ev.reshape(1,-1)\n",
    "        sim = cosine_similarity(ev,cluster_center_vectors)\n",
    "        sim_max = np.max(sim)\n",
    "        if sim_max<th:\n",
    "            ress.append(-1)\n",
    "        else:\n",
    "            ress.append(keys[np.argmax(sim)])\n",
    "\n",
    "    return np.array(ress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pick(x,n):\n",
    "    if int(x[0]+x[1]-1) <n:\n",
    "        pa = n\n",
    "    else:\n",
    "        pa = int(x[0]+x[1]-1)\n",
    "    p = np.random.choice(pa, n,replace=False)\n",
    "    picked  = list(map(lambda y: 0 if x[0]>y  else 1 , p))\n",
    "    if len(np.unique(picked)) ==2:\n",
    "        output = -1\n",
    "    else:\n",
    "        output = picked[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_labeling(res,train_label,n):\n",
    "    df = pd.DataFrame([res,train_label])\n",
    "    df = df.transpose()\n",
    "    df.columns = ['pred','label']\n",
    "    values = df.groupby('pred').value_counts().reset_index()\n",
    "    card = df.groupby('pred').value_counts().reset_index().groupby('pred').nunique().reset_index()\n",
    "    card.columns = ['pred','label','card']\n",
    "    card[0]=0\n",
    "    card[1]=0\n",
    "\n",
    "    for _,i in values.iterrows():\n",
    "        card.loc[card.pred == i['pred'],i.label] = i[0]\n",
    "\n",
    "    card['ratio'] = card[1]/(card[0] + card[1])\n",
    "\n",
    "    card['random_pick'] = card.apply(random_pick,axis=1,n=n)\n",
    "    cluster_label = card.set_index('pred').random_pick.to_dict()\n",
    "    return card,cluster_label\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(card,pred,cluster_label):\n",
    "    pred_ = np.array(list(map(lambda x: cluster_label[x],pred)), dtype=np.int32)\n",
    "    return pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_private_dataset(path):\n",
    "    df= pd.read_csv(path)\n",
    "    df = df[~df.encrypt]\n",
    "    idx = df.index\n",
    "    train_idx, test_idx = train_test_split(idx,test_size=0.2,shuffle=False)\n",
    "    df['decoded'] = df.payload.apply(hex2ascii)\n",
    "    train_ = df.loc[train_idx]\n",
    "    test_ = df.loc[test_idx]\n",
    "\n",
    "\n",
    "    train_label = df.loc[train_idx, 'analyResult'].to_numpy()\n",
    "    test_label = df.loc[test_idx, 'analyResult'].to_numpy()\n",
    "\n",
    "    return train_,test_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 오픈 데이터셋 실험 코드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "th = 0.95\n",
    "n = 1\n",
    "\n",
    "# train, test_ ,train_label,test_label =  read_opendata('./dataset/')\n",
    "\n",
    "res = do_v2(train,512,4,th,th,3)\n",
    "\n",
    "test = res[-1].transform(test_)\n",
    "\n",
    "cluster_center = find_centroid(res,test,th)\n",
    "\n",
    "pred = find_centroid(res,test,th)\n",
    "\n",
    "card,cluster_label = clustering_labeling(res[0],train_label,n)\n",
    "\n",
    "pred_ = testing(card,pred,cluster_label)\n",
    "coverage_index = pred!=-1\n",
    "\n",
    "f1  = f1_score(test_label[coverage_index],pred_[coverage_index])\n",
    "\n",
    "coverage = coverage_index.sum()/coverage_index.shape[0]\n",
    "\n",
    "card,cluster_label = clustering_labeling(res[0],train_label,n)\n",
    "\n",
    "pred_ = testing(card,pred,cluster_label)\n",
    "coverage_index = pred!=-1\n",
    "\n",
    "f1  = f1_score(test_label[coverage_index],pred_[coverage_index])\n",
    "\n",
    "coverage = coverage_index.sum()/coverage_index.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 kisti 데이터셋 실험 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# public datase\n",
    "\n",
    "th_ = np.arange(0.1,0.99,0.05)\n",
    "\n",
    "res_={}\n",
    "\n",
    "train_, test_ = read_private_dataset('./dataset/public.csv')\n",
    "\n",
    "for th in th_:\n",
    "    n = 1\n",
    "    min_count = 3\n",
    "    vector_size= 512\n",
    "    # train, test_ ,train_label,test_label =  read_opendata('./dataset/')\n",
    "\n",
    "    pred_all, coverage_all = [[],[]],[0,0]\n",
    "\n",
    "    no_iip=0\n",
    "    remain_out = 0\n",
    "    for iip in tqdm(train_.machine.unique()):\n",
    "        for na in train_.detectName.unique():\n",
    "            train = train_[(train_.machine==iip)&(train_.detectName==na)]\n",
    "            \n",
    "            test = test_[(test_.machine==iip)&(test_.detectName==na)]\n",
    "\n",
    "            train_label = train.analyResult.to_numpy()\n",
    "            test_label = test.analyResult.to_numpy()\n",
    "\n",
    "            train_decoded = train.decoded\n",
    "            test_decoded = test.decoded\n",
    "\n",
    "            if len(test)==0:\n",
    "                continue\n",
    "            \n",
    "            if len(train)<=min_count:\n",
    "                no_iip+=len(test)\n",
    "                continue\n",
    "\n",
    "            res = do_v2(train_decoded,vector_size,4,th,th,min_count)\n",
    "\n",
    "            test = res[-1].transform(test_decoded)\n",
    "\n",
    "            cluster_center = find_centroid(res,test,th)\n",
    "\n",
    "            pred = find_centroid(res,test,th)\n",
    "\n",
    "            card,cluster_label = clustering_labeling(res[0],train_label,n)\n",
    "            cluster_label[-1]=-1\n",
    "            pred_ = testing(card,pred,cluster_label)\n",
    "            coverage_index = pred_!=-1\n",
    "            remain_out += np.sum(pred==-1)\n",
    "            coverage = (coverage_index.sum(),coverage_index.shape[0])\n",
    "            \n",
    "            pred_all[0].extend(test_label[coverage_index])\n",
    "            pred_all[1].extend(pred_[coverage_index])\n",
    "            coverage_all[0]+=coverage_index.sum()\n",
    "            coverage_all[1]+=coverage_index.shape[0]\n",
    "    \n",
    "    res_[th] = (pred_all,coverage_all,no_iip,remain_out)\n",
    "\n",
    "f1_ = []\n",
    "cover = []\n",
    "for th in res_:\n",
    "    f1_.append(f1_score(res_[th][0][0],res_[th][0][1]))\n",
    "    cover.append(res_[th][1][0]/res_[th][1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[th,f1,coverage]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('deepcase')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65fff2cfb182d60db35454cc37f65ab1b44494357178ffadfbb27a8abfc5c322"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
